{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "51630f9744cb41a084b4c9ed1439d63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdd14e42f7c54cb28c2f33d2067617d7",
              "IPY_MODEL_dd9a6d7ab5c643e7adf39533c86526a4",
              "IPY_MODEL_30c1aa46a66c4ee79f217ae50cdb75cb"
            ],
            "layout": "IPY_MODEL_10f72eb973ff4ddfb9b1e19091c69ea7"
          }
        },
        "bdd14e42f7c54cb28c2f33d2067617d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35c2b627b3f54ae8bab4aaa1d7c1ccf3",
            "placeholder": "​",
            "style": "IPY_MODEL_e0cf1c1d9a664753ace7eb2622446b2a",
            "value": "Downloading builder script: 100%"
          }
        },
        "dd9a6d7ab5c643e7adf39533c86526a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dc6ef2b37cb48bc812a04760868ac10",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c528c498b58e4130a813bcf7693a8a90",
            "value": 4203
          }
        },
        "30c1aa46a66c4ee79f217ae50cdb75cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97de7d08033a4855b6430b50e2ac3b44",
            "placeholder": "​",
            "style": "IPY_MODEL_fd48cef767fd432da50ffa5d4221e260",
            "value": " 4.20k/4.20k [00:00&lt;00:00, 270kB/s]"
          }
        },
        "10f72eb973ff4ddfb9b1e19091c69ea7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35c2b627b3f54ae8bab4aaa1d7c1ccf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0cf1c1d9a664753ace7eb2622446b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dc6ef2b37cb48bc812a04760868ac10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c528c498b58e4130a813bcf7693a8a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97de7d08033a4855b6430b50e2ac3b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd48cef767fd432da50ffa5d4221e260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0QpNxmuMTyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe9da30d-857a-4aef-e0aa-a19f0e04c5af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.10/dist-packages (7.352.0)\n",
            "Requirement already satisfied: peft==0.4.0 in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (4.46.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (1.1.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.4.0) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->peft==0.4.0) (0.26.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0) (4.66.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.4.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets evaluate accelerate trl\n",
        "!pip install nvidia-ml-py3\n",
        "!pip install -U peft==0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from pynvml import *\n",
        "\n",
        "# Install required packages using pip\n",
        "packages = [\n",
        "    \"transformers\", \"datasets\", \"evaluate\", \"accelerate\", \"peft\", \"trl\",\n",
        "    \"nvidia-ml-py3\"\n",
        "]\n",
        "for package in packages:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])"
      ],
      "metadata": {
        "id": "lsfj9ucZTCtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary ML libraries\n",
        "import torch\n",
        "from transformers import RobertaModel, RobertaTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, BitsAndBytesConfig, GPT2Tokenizer, GPT2ForSequenceClassification\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "mUpB2_XCTCq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LoRA (Low-Rank Adaptation) hyperparameters\n",
        "lora_r = 8\n",
        "lora_alpha = 16\n",
        "output_dir = './lora_results_prompt_tuning'\n",
        "\n",
        "# Initialize Weights & Biases for experiment tracking\n",
        "import wandb\n",
        "wandb.login()\n",
        "run_name = \"LoRA_adapt_tuning\"\n",
        "wandb.init(\n",
        "    project=\"Lora\",\n",
        "    name=run_name,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "_R9t-bO_TCo2",
        "outputId": "2069d6b1-e410-425e-f208-da67e10fe107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myanjie98\u001b[0m (\u001b[33myanjie98-new-york-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241212_012716-4644vs31</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yanjie98-new-york-university/Lora/runs/4644vs31' target=\"_blank\">LoRA_adapt_tuning</a></strong> to <a href='https://wandb.ai/yanjie98-new-york-university/Lora' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yanjie98-new-york-university/Lora' target=\"_blank\">https://wandb.ai/yanjie98-new-york-university/Lora</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yanjie98-new-york-university/Lora/runs/4644vs31' target=\"_blank\">https://wandb.ai/yanjie98-new-york-university/Lora/runs/4644vs31</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/yanjie98-new-york-university/Lora/runs/4644vs31?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7e088f9b89d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the base model and tokenizer\n",
        "base_model = 'gpt2'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(base_model)\n",
        "tokenizer.pad_token = tokenizer.eos_token  # GPT2 doesn't have a pad token by default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SWdom4DTCmm",
        "outputId": "56c9ec66-766c-4f5f-89c3-3d08eadae8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the AG News dataset and prepare a subset for training\n",
        "dataset = load_dataset('ag_news')\n",
        "train_size = 1000\n",
        "\n",
        "def preprocess(examples):\n",
        "    \"\"\"\n",
        "    Preprocess the dataset by tokenizing the input texts\n",
        "    Args:\n",
        "        examples: Raw text examples from dataset\n",
        "    Returns:\n",
        "        Tokenized and formatted examples\n",
        "    \"\"\"\n",
        "    tokenized = tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128\n",
        "    )\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "FZlcmIKuTCkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare train, eval, and test datasets\n",
        "tokenized_dataset = dataset.map(preprocess, batched=True,  remove_columns=[\"text\"])\n",
        "train_dataset=tokenized_dataset['train']\n",
        "eval_dataset=tokenized_dataset['test'].shard(num_shards=2, index=0)\n",
        "test_dataset=tokenized_dataset['test'].shard(num_shards=2, index=1)\n",
        "\n",
        "\n",
        "# Extract the number of classess and their names\n",
        "num_labels = dataset['train'].features['label'].num_classes\n",
        "class_names = dataset[\"train\"].features[\"label\"].names\n",
        "# Get label information\n",
        "num_labels = dataset['train'].features['label'].num_classes\n",
        "class_names = dataset[\"train\"].features[\"label\"].names\n",
        "print(f\"number of labels: {num_labels}\")\n",
        "print(f\"the labels: {class_names}\")\n",
        "\n",
        "id2label = {i: label for i, label in enumerate(class_names)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t1Dc3f6TCh1",
        "outputId": "63d1dc4e-18e2-4d12-92ae-d81da0d1f60f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of labels: 4\n",
            "the labels: ['World', 'Sports', 'Business', 'Sci/Tech']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure data collator for padding batches\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
        "\n",
        "# Initialize the GPT2 model for sequence classification\n",
        "model = GPT2ForSequenceClassification.from_pretrained(\n",
        "    base_model,\n",
        "    id2label=id2label,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        ")\n",
        "\n",
        "# Configure LoRA parameters for efficient fine-tuning\n",
        "peft_config = LoraConfig(\n",
        "    r=lora_r,  # Rank dimension\n",
        "    lora_alpha=lora_alpha,  # Scaling factor\n",
        "    lora_dropout=0.05,  # Dropout probability for LoRA layers\n",
        "    bias='none',  # Don't train bias parameters\n",
        "    task_type=\"SEQ_CLS\",  # Sequence classification task\n",
        "    target_modules=['c_attn', 'c_proj'],  # Layers to apply LoRA\n",
        ")\n",
        "\n",
        "# Apply LoRA configuration to the model\n",
        "model = get_peft_model(model, peft_config)\n",
        "model\n",
        "\n",
        "print('PEFT Model')\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odcOGDHkTCfd",
        "outputId": "ffc32e82-902b-4736-9072-954b791d022a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py:299: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PEFT Model\n",
            "trainable params: 817,152 || all params: 125,256,960 || trainable%: 0.6523805144241086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaptLayer(nn.Module):\n",
        "    def __init__(self, hidden_size, adapter_size):\n",
        "        super().__init__()\n",
        "        self.down_project = nn.Linear(hidden_size, adapter_size)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.up_project = nn.Linear(adapter_size, hidden_size)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.down_project(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.up_project(x)\n",
        "        x = x + residual\n",
        "        x = self.layer_norm(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Mt1OOcLyeres"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add adapter layers to each transformer block for additional fine-tuning capability\n",
        "adapter_size = 64  # Hidden dimension of adapter layers\n",
        "for name, module in model.named_modules():\n",
        "    if \"transformer.h\" in name and name.endswith(\".mlp\"):\n",
        "        # Get output dimension of MLP layer\n",
        "        hidden_size = module.c_proj.out_features\n",
        "        # Initialize adapter layer\n",
        "        adapter = AdaptLayer(hidden_size, adapter_size)\n",
        "        # Move adapter to same device as model\n",
        "        adapter.to(model.device)\n",
        "        setattr(module, \"adapter\", adapter)"
      ],
      "metadata": {
        "id": "0WQIbZ_Ad1r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_forward(model):\n",
        "    \"\"\"\n",
        "    Modify the model's forward pass to include adapter layers\n",
        "    Args:\n",
        "        model: The model to modify\n",
        "    \"\"\"\n",
        "    old_forward = model.forward\n",
        "\n",
        "    def new_forward(self, *args, **kwargs):\n",
        "        outputs = old_forward(*args, **kwargs)\n",
        "\n",
        "        # Apply adapter after each MLP layer\n",
        "        for module in self.modules():\n",
        "            if hasattr(module, \"adapter\"):\n",
        "                if isinstance(outputs, tuple):\n",
        "                    outputs = (module.adapter(outputs[0]),) + outputs[1:]\n",
        "                else:\n",
        "                    outputs = module.adapter(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    model.forward = new_forward.__get__(model)"
      ],
      "metadata": {
        "id": "Rl6HhHtld2xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    evaluation_strategy='steps',  # Evaluate during training\n",
        "    learning_rate=5e-5,  # Learning rate for optimization\n",
        "    num_train_epochs=1,  # Number of training epochs\n",
        "    use_cpu=False,  # Use GPU if available\n",
        "    dataloader_num_workers=1,  # Number of parallel data loading workers\n",
        "    per_device_train_batch_size=16,  # Batch size per device\n",
        "    optim=\"adamw_torch\",  # Use AdamW optimizer\n",
        "    gradient_checkpointing=False,  # Disable gradient checkpointing\n",
        "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THhpQY1ld2uP",
        "outputId": "cba47dbf-97b0-4909-a335-3df77cf5e694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_trainer(model):\n",
        "    \"\"\"\n",
        "    Initialize trainer with model and training configuration\n",
        "    Args:\n",
        "        model: Model to be trained\n",
        "    Returns:\n",
        "        Configured Trainer instance for model training\n",
        "    \"\"\"\n",
        "    return Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        compute_metrics=compute_metrics,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        data_collator=data_collator,\n",
        "    )"
      ],
      "metadata": {
        "id": "63uFjKU7d2rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize evaluation metric\n",
        "metric = evaluate.load('accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "51630f9744cb41a084b4c9ed1439d63f",
            "bdd14e42f7c54cb28c2f33d2067617d7",
            "dd9a6d7ab5c643e7adf39533c86526a4",
            "30c1aa46a66c4ee79f217ae50cdb75cb",
            "10f72eb973ff4ddfb9b1e19091c69ea7",
            "35c2b627b3f54ae8bab4aaa1d7c1ccf3",
            "e0cf1c1d9a664753ace7eb2622446b2a",
            "0dc6ef2b37cb48bc812a04760868ac10",
            "c528c498b58e4130a813bcf7693a8a90",
            "97de7d08033a4855b6430b50e2ac3b44",
            "fd48cef767fd432da50ffa5d4221e260"
          ]
        },
        "id": "-x9AaUnnh1Ff",
        "outputId": "cc7132ef-01fa-4fe5-8e2e-54f5bdb0aed3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51630f9744cb41a084b4c9ed1439d63f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_gpu_utilization():\n",
        "\n",
        "    nvmlInit()\n",
        "    handle = nvmlDeviceGetHandleByIndex(0)\n",
        "    info = nvmlDeviceGetMemoryInfo(handle)\n",
        "    print(f\"GPU memory: {info.used//1024**2} MB\")\n",
        "def print_summary(result):\n",
        "    print(f\"training time: {result.metrics['train_runtime']:.2f}\")\n",
        "    print(f\"step training time: {result.metrics['train_samples_per_second']:.2f}\")\n",
        "    print(f\"training loss: {result.metrics['train_loss']:.2f}\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "MBlU0PBJd2hV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize trainer with LoRA-configured model\n",
        "peft_lora_finetuning_trainer = get_trainer(model)\n",
        "\n",
        "# Start training process\n",
        "result = peft_lora_finetuning_trainer.train()\n",
        "\n",
        "# End wandb logging session\n",
        "wandb.finish()\n",
        "\n",
        "# Print final GPU utilization\n",
        "print_gpu_utilization()\n",
        "\n",
        "# Print training summary\n",
        "print_summary(result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4fbb096a7504413f9a3453ecab125279"
          ]
        },
        "id": "PdQgoecvd2om",
        "outputId": "43aa2b42-3809-4be2-cbc8-d3350a14a55a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7500/7500 12:12, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.298100</td>\n",
              "      <td>0.343052</td>\n",
              "      <td>0.887105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.297100</td>\n",
              "      <td>0.322159</td>\n",
              "      <td>0.893421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.294400</td>\n",
              "      <td>0.307041</td>\n",
              "      <td>0.898947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.275900</td>\n",
              "      <td>0.312155</td>\n",
              "      <td>0.901053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.289000</td>\n",
              "      <td>0.293932</td>\n",
              "      <td>0.897895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.293600</td>\n",
              "      <td>0.282731</td>\n",
              "      <td>0.902368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.268400</td>\n",
              "      <td>0.272026</td>\n",
              "      <td>0.906842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.264800</td>\n",
              "      <td>0.289347</td>\n",
              "      <td>0.904474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>0.271230</td>\n",
              "      <td>0.910526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.254800</td>\n",
              "      <td>0.288718</td>\n",
              "      <td>0.907105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.259000</td>\n",
              "      <td>0.265093</td>\n",
              "      <td>0.913947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.253600</td>\n",
              "      <td>0.273122</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.264000</td>\n",
              "      <td>0.268824</td>\n",
              "      <td>0.911579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.254800</td>\n",
              "      <td>0.266310</td>\n",
              "      <td>0.912632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.264400</td>\n",
              "      <td>0.266090</td>\n",
              "      <td>0.913158</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='1.746 MB of 10.721 MB uploaded\\r'), FloatProgress(value=0.1629014342571999, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fbb096a7504413f9a3453ecab125279"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃▄▅▄▅▆▆▇▆█▇▇██</td></tr><tr><td>eval/loss</td><td>█▆▅▅▄▃▂▃▂▃▁▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▄▄▅▃▁▁▄▄▁▅▄█▄▃</td></tr><tr><td>eval/samples_per_second</td><td>▆▅▅▄▆██▅▅█▄▅▁▅▆</td></tr><tr><td>eval/steps_per_second</td><td>▆▅▅▄▆██▅▅█▄▅▁▅▆</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▁▂▂▃▂▇▁▂▅█▇▄▃▅▄▂▂</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▆▅▅▅▄▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91316</td></tr><tr><td>eval/loss</td><td>0.26609</td></tr><tr><td>eval/runtime</td><td>8.4677</td></tr><tr><td>eval/samples_per_second</td><td>448.763</td></tr><tr><td>eval/steps_per_second</td><td>56.095</td></tr><tr><td>total_flos</td><td>8025404866560000.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>7500</td></tr><tr><td>train/grad_norm</td><td>7.77146</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>0.2644</td></tr><tr><td>train_loss</td><td>0.27346</td></tr><tr><td>train_runtime</td><td>732.908</td></tr><tr><td>train_samples_per_second</td><td>163.731</td></tr><tr><td>train_steps_per_second</td><td>10.233</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">LoRA_adapt_tuning</strong> at: <a href='https://wandb.ai/yanjie98-new-york-university/Lora/runs/4644vs31' target=\"_blank\">https://wandb.ai/yanjie98-new-york-university/Lora/runs/4644vs31</a><br/> View project at: <a href='https://wandb.ai/yanjie98-new-york-university/Lora' target=\"_blank\">https://wandb.ai/yanjie98-new-york-university/Lora</a><br/>Synced 4 W&B file(s), 0 media file(s), 46 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241212_012716-4644vs31/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU memory: 4259 MB\n",
            "training time: 732.91\n",
            "step training time: 163.73\n",
            "training loss: 0.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataset):\n",
        "\n",
        "    trainer = get_trainer(model)\n",
        "    metrics = trainer.evaluate(dataset)\n",
        "    print(f\"result: {metrics}\")"
      ],
      "metadata": {
        "id": "ApLlcKGlg6w3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and evaluate base model for comparison\n",
        "base_model_for_eval = GPT2ForSequenceClassification.from_pretrained(\n",
        "    base_model,\n",
        "    id2label=id2label,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "# Evaluate both base model and fine-tuned model\n",
        "evaluate_model(base_model_for_eval, test_dataset)\n",
        "evaluate_model(model, test_dataset)"
      ],
      "metadata": {
        "id": "g3UMuDZAd2ns",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "e9a2a930-069f-4593-be0a-ab0077eb5220"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [475/475 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241212_015541-kbz52z5b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yanjie98-new-york-university/huggingface/runs/kbz52z5b' target=\"_blank\">./lora_results_prompt_tuning</a></strong> to <a href='https://wandb.ai/yanjie98-new-york-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yanjie98-new-york-university/huggingface' target=\"_blank\">https://wandb.ai/yanjie98-new-york-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yanjie98-new-york-university/huggingface/runs/kbz52z5b' target=\"_blank\">https://wandb.ai/yanjie98-new-york-university/huggingface/runs/kbz52z5b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result: {'eval_loss': 7.05778694152832, 'eval_model_preparation_time': 0.0025, 'eval_accuracy': 0.25973684210526315, 'eval_runtime': 7.3683, 'eval_samples_per_second': 515.722, 'eval_steps_per_second': 64.465}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [475/475 00:08]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result: {'eval_loss': 0.23249667882919312, 'eval_model_preparation_time': 0.007, 'eval_accuracy': 0.9189473684210526, 'eval_runtime': 8.7908, 'eval_samples_per_second': 432.27, 'eval_steps_per_second': 54.034}\n"
          ]
        }
      ]
    }
  ]
}